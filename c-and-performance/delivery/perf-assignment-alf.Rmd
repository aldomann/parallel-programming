---
title: "Parallel Programming"
subtitle: "C Programming and Performance Delivery"
author: "Alfredo Hernández & Alejandro Jiménez"
date: "27 October 2017"
output:
  pdf_document:
      toc: yes
  html_notebook:
    highlight: pygments
    theme: cosmo
    toc: yes
---
# Goals
- Understand the algorithm and its computational model (complexity, problem size).
- Performance engineer the code: optimize the serial execution and understand where is the performance bottleneck.
- Identify opportunities of vectorization (use of SIMD instructions) and improvement of the memory accesses.

# Detailed Schedule

1. Select one of the applications described in this document. Define the operation related to the application that will be used as a unit to measure the performance (operations/second). Estimate the algorithmic complexity of the application: i.e., find a formula to compute the total number of operations performed as a function of the problem size (one or more parameters related to the input of the application).
2. Compile the base version of the program and measure relevant performance metrics (time, instructions executed, IPC). Select a problem size that is big enough for the execution to take several seconds. Determine a way to check that the output of the program is correct: remember that the discrete nature of the mathematical operations using real numbers (floating-point) implemented in the computer means that the associative property does not hold for additions and multiplies. Therefore, changes in the order of the operations may generate slight variations in the results that can grow if the accumulated error diverges.
3. Measure execution time to check the effect of the problem size on performance. Identify the time taken by the initialization stages and the time taken by the main part of the algorithm. Ideally, the initialization part should be relatively less and less important as the problem size grows. By selecting the data type used for real numbers, either float or double, you can test the effect both on performance and functionality.
4. You can check the performance differences of the code generated by different compilers (different versions of the gnu gcc or intel icc) and using different compilation flags or options.
5. Improve the program implementation of the serial (or single-thread) baseline code in order to achieve better performance. There are several classical optimizations that you should consider: loop interchange (or reordering), code motion, strength reduction, ... Ask for help to your teacher. Explain your results, both when the optimizations succeed and when they fail.
6. Improve the program implementation of the serial code in order to take advantage of the SIMD or vector instructions available in the processor. Ask the teacher if you need help. 
7. Find out the performance bottleneck of the program (using perf ). Ask the teacher if you need help.

# Report

## Bash scripts
```{bash eval=FALSE}
#!/bin/bash
NX=$1; NY=$2; NZ=$3; executable=$4; perfoutfile=$5

if [ ! -f $perfoutfile ]; then
	touch $perfoutfile
	echo "iter,nx,ny,nz,cycl,inst,time" >> $perfoutfile
fi

perf stat -o perf-out.txt -e cycles,instructions ./$executable $NX $NY $NZ | awk '{ print $8 }' ORS="," >> $perfoutfile
awk '/stats/ { printf ("%d,%d,%d,", $6, $7, $8) }' perf-out.txt >> $perfoutfile
awk '/cycles/ { gsub(/\./,"",$1); print $1 }' ORS="," perf-out.txt >> $perfoutfile
awk '/instructions/ { gsub(/\./,"",$1); print $1 }' ORS="," perf-out.txt >> $perfoutfile
awk '/elapsed/ { gsub(/,/,".",$1);print $1 }' perf-out.txt >> $perfoutfile

rm perf-out.txt
```


## R script

```{r include=FALSE}
source("diff-plots.R")
```

```{r message=FALSE}
# Accuracy + init
df.float <- read_results("perftime-base-float.csv", "float")
df.double <- read_results("perftime-base-double.csv", "double")
# Flags
df.no <- read_results("perftime-no.csv", "base")
df.o2 <- read_results("perftime-o2.csv", "-O2")
df.o3 <- read_results("perftime-o3.csv", "-O3")
# Optimisations
df.bs <- read_results("perftime-base.csv", "base")
df.nt <- read_results("perftime-notime.csv", "no time")
df.nt.gl <- read_results("perftime-notime-goodloop.csv", "no time + good loop")

# Rbinds
df.acc <- rbind(df.float, df.double)
df.flags <- rbind(df.no, df.o2, df.o3)
df.opts <- rbind(df.bs, df.nt, df.nt.gl)
```

```{r}
get_acc_plots(df.acc)
get_perf_plots(df.acc, "(comparing var type)")
```

```{r}
get_time_plots(df.double)
```

```{r}
get_perf_plots(df.flags, "(comparing compiler flags)")
```

```{r}
get_perf_plots(df.opts, "(comparing optimisations)")
```



